{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b73db75-633e-4cee-a5e2-bccec11560bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: numpy in r:\\annaconda new\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in r:\\annaconda new\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in r:\\annaconda new\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in r:\\annaconda new\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in r:\\annaconda new\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in r:\\annaconda new\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in r:\\annaconda new\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in r:\\annaconda new\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in r:\\annaconda new\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302324c-96a9-414f-8f02-86d31b74c627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300, Loss: 0.2343\n",
      "Epoch 100/300, Loss: 0.2205\n",
      "Epoch 150/300, Loss: 0.2145\n",
      "Epoch 200/300, Loss: 0.2117\n",
      "Epoch 250/300, Loss: 0.2101\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Sample text data\n",
    "text = \"deep learning is amazing. text generation using lstm networks is powerful.\"\n",
    "\n",
    "# Unique characters\n",
    "chars = sorted(list(set(text)))\n",
    "char2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "\n",
    "vocab_size = len(chars)\n",
    "seq_length = 40\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "lr = 0.003\n",
    "num_epochs = 300\n",
    "\n",
    "# Prepare dataset\n",
    "data = [char2idx[ch] for ch in text]\n",
    "\n",
    "def get_batches(data, seq_length):\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data[i+1:i+seq_length+1]\n",
    "        yield torch.tensor(x).unsqueeze(0), torch.tensor(y).unsqueeze(0)\n",
    "\n",
    "# Define the LSTM model\n",
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (\n",
    "            torch.zeros(num_layers, batch_size, hidden_size),\n",
    "            torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        )\n",
    "\n",
    "# Initialize model\n",
    "model = CharLSTM(vocab_size, hidden_size, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    hidden = model.init_hidden()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in get_batches(data, seq_length):\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(x, hidden)\n",
    "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        hidden = tuple([h.detach() for h in hidden])\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Generate text\n",
    "def generate_text(start_char='d', length=200):\n",
    "    model.eval()\n",
    "    input = torch.tensor([[char2idx[start_char]]])\n",
    "    hidden = model.init_hidden()\n",
    "    result = [start_char]\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input, hidden)\n",
    "        probs = torch.softmax(output[0, -1], dim=0).detach().numpy()\n",
    "        next_idx = np.random.choice(vocab_size, p=probs)\n",
    "        next_char = idx2char[next_idx]\n",
    "        result.append(next_char)\n",
    "        input = torch.tensor([[next_idx]])\n",
    "\n",
    "    return ''.join(result)\n",
    "\n",
    "# ðŸ”¥ Sample output\n",
    "print(\"\\nGenerated Text:\\n\")\n",
    "print(generate_text('d', 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae476c-ecbf-4ee4-b086-18b3d0bac849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
